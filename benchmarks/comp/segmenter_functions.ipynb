{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generating a random E matrix to simulate embedded features\n",
    "np.random.seed(0)  # For reproducibility\n",
    "E = np.random.rand(5000, 10)  # 500 data points with 10 dimensions\n",
    "\n",
    "E.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def compute_recurrence_matrix_librosa(E, k=0.04):\n",
    "    \"\"\"Compute the recurrence matrix using the original method.\"\"\"\n",
    "    N = E.shape[0]\n",
    "    k_val = int(k * N)\n",
    "    R = librosa.segment.recurrence_matrix(E.T, k=k_val, width=1, metric=\"euclidean\", sym=True).astype(np.float32)\n",
    "    return R\n",
    "\n",
    "# Let's test the original method to ensure it works correctly\n",
    "R_Librosa = compute_recurrence_matrix_librosa(E)\n",
    "R_Librosa.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "def compute_recurrence_matrix_annoy(E, k=0.04):\n",
    "    \"\"\"Compute the recurrence matrix using Annoy for approximate nearest neighbors.\"\"\"\n",
    "    N, D = E.shape\n",
    "    k_val = int(k * N)\n",
    "    R = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "    # Build the Annoy index\n",
    "    t = AnnoyIndex(D, metric='euclidean')\n",
    "    for i in range(N):\n",
    "        t.add_item(i, E[i])\n",
    "    t.build(10)  # 10 trees for the index\n",
    "\n",
    "    # Find the k nearest neighbors for each point\n",
    "    for i in range(N):\n",
    "        neighbors = t.get_nns_by_item(i, k_val)\n",
    "        R[i, neighbors] = 1\n",
    "\n",
    "    return R\n",
    "\n",
    "# Let's test the Annoy method to ensure it works correctly\n",
    "R_annoy = compute_recurrence_matrix_annoy(E)\n",
    "R_annoy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def pairwise_distance_parallel(i, E):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance for a given row index i.\n",
    "    \"\"\"\n",
    "    return distance.cdist([E[i]], E, 'euclidean').flatten()\n",
    "\n",
    "def parallel_recurrence_matrix(E, k):\n",
    "    \"\"\"\n",
    "    Compute the recurrence matrix using parallel processing.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances in parallel\n",
    "    pairwise_distances = np.array(Parallel(n_jobs=-1)(delayed(pairwise_distance_parallel)(i, E) for i in range(E.shape[0])))\n",
    "    \n",
    "    # Create the recurrence matrix based on k-nearest neighbors\n",
    "    sort_idx = np.argsort(pairwise_distances, axis=1)\n",
    "    nearest_idx = sort_idx[:, :int(k*E.shape[0])]\n",
    "    \n",
    "    R_parallel = np.zeros(pairwise_distances.shape, dtype=np.float32)\n",
    "    for i in range(E.shape[0]):\n",
    "        R_parallel[i, nearest_idx[i]] = 1\n",
    "\n",
    "    return R_parallel\n",
    "\n",
    "# Let's test the parallel method to ensure it works correctly\n",
    "R_parallel = parallel_recurrence_matrix(E, k=0.04)\n",
    "R_parallel.shape\n",
    "\n",
    "# Run the approximate assertions\n",
    "assert np.allclose(R_Librosa, R_parallel), \"Librosa and parallel methods do not match!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "def vectorized_recurrence_matrix(E, k):\n",
    "    \"\"\"\n",
    "    Compute the recurrence matrix using a vectorized approach.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    pairwise_distances = distance.cdist(E, E, 'euclidean')\n",
    "    \n",
    "    # Create the recurrence matrix based on k-nearest neighbors\n",
    "    sort_idx = np.argsort(pairwise_distances, axis=1)\n",
    "    nearest_idx = sort_idx[:, :int(k*E.shape[0])]\n",
    "    \n",
    "    R_vectorized = np.zeros(pairwise_distances.shape, dtype=np.float32)\n",
    "    for i in range(E.shape[0]):\n",
    "        R_vectorized[i, nearest_idx[i]] = 1\n",
    "\n",
    "    return R_vectorized\n",
    "\n",
    "# Let's test the vectorized method to ensure it works correctly\n",
    "R_vectorized = vectorized_recurrence_matrix(E, k=0.04)\n",
    "R_vectorized.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_recurrence_matrix(E, k=0.04):\n",
    "    \"\"\"Compute the recurrence matrix using pairwise distance computations.\"\"\"\n",
    "    N = E.shape[0]\n",
    "    k_val = int(k * N)\n",
    "    R = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Compute pairwise distances to all other points\n",
    "        distances = np.linalg.norm(E[i] - E, axis=1)\n",
    "        \n",
    "        # Find the k smallest distances\n",
    "        k_smallest_indices = np.argpartition(distances, k_val)[:k_val]\n",
    "        \n",
    "        # Set the recurrence matrix values for these indices\n",
    "        R[i, k_smallest_indices] = 1\n",
    "    \n",
    "    return R\n",
    "\n",
    "# Let's test the pairwise distance method to ensure it works correctly\n",
    "R_pairwise = compute_recurrence_matrix(E)\n",
    "R_pairwise.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa method: 20.10 seconds\n",
      "Annoy method: 9.23 seconds\n",
      "Numpy method: 8.54 seconds\n",
      "Parallel method: 19.16 seconds\n",
      "Vectorized method: 15.02 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Define the number of repetitions for benchmarking\n",
    "repetitions = 3\n",
    "\n",
    "# Benchmark the original method\n",
    "time_librosa = timeit.timeit(lambda: compute_recurrence_matrix_librosa(E), number=repetitions)\n",
    "\n",
    "# Benchmark the Annoy method\n",
    "time_annoy = timeit.timeit(lambda: compute_recurrence_matrix_annoy(E), number=repetitions)\n",
    "\n",
    "# Benchmark the numpy-optimized method\n",
    "\n",
    "time_numpy_optimized = timeit.timeit(lambda: compute_recurrence_matrix(E), number=repetitions)\n",
    "\n",
    "# Benchmark the parallel method\n",
    "time_parallel = timeit.timeit(lambda: parallel_recurrence_matrix(E, k=0.04), number=repetitions)\n",
    "\n",
    "# Benchmark the vectorized method\n",
    "time_vectorized = timeit.timeit(lambda: vectorized_recurrence_matrix(E, k=0.04), number=repetitions)\n",
    "\n",
    "\n",
    "print(\"Librosa method: {:.2f} seconds\".format(time_librosa))\n",
    "print(\"Annoy method: {:.2f} seconds\".format(time_annoy))\n",
    "print(\"Numpy method: {:.2f} seconds\".format(time_numpy_optimized))\n",
    "print(\"Parallel method: {:.2f} seconds\".format(time_parallel))\n",
    "print(\"Vectorized method: {:.2f} seconds\".format(time_vectorized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 2\n",
    "E = np.random.rand(10000, 10)  # 500 data points with 10 dimensions\n",
    "\n",
    "# Benchmark the Annoy method\n",
    "time_annoy = timeit.timeit(lambda: compute_recurrence_matrix_annoy(E), number=repetitions)\n",
    "\n",
    "# Benchmark the numpy-optimized method\n",
    "time_numpy_optimized = timeit.timeit(lambda: compute_recurrence_matrix(E), number=repetitions)\n",
    "\n",
    "# Benchmark the vectorized method\n",
    "time_vectorized = timeit.timeit(lambda: vectorized_recurrence_matrix(E, k=0.04), number=repetitions)\n",
    "\n",
    "print(\"Annoy method: {:.2f} seconds\".format(time_annoy))\n",
    "print(\"Numpy method: {:.2f} seconds\".format(time_numpy_optimized))\n",
    "print(\"Vectorized method: {:.2f} seconds\".format(time_vectorized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa method: 20.10 seconds\n",
      "Annoy method: 7.53 seconds\n",
      "Numpy method: 7.02 seconds\n",
      "Parallel method: 19.16 seconds\n",
      "Vectorized method: 14.18 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_novelty_curve_optimized(X):\n",
    "    \"\"\"\n",
    "    Computes the novelty curve from the structural features using vectorized operations.\n",
    "\n",
    "    Args:\n",
    "    - X (np.array): Structural features.\n",
    "\n",
    "    Returns:\n",
    "    - nc (np.array): Novelty curve.\n",
    "    \"\"\"\n",
    "    # Compute Euclidean distance between consecutive feature vectors\n",
    "    diffs = np.diff(X, axis=0)\n",
    "    nc = np.linalg.norm(diffs, axis=1)\n",
    "\n",
    "    # Append a zero at the end to match the size of the original function's output\n",
    "    nc = np.append(nc, 0)\n",
    "\n",
    "    # Normalize the novelty curve to a range [0, 1]\n",
    "    if nc.max() != 0:\n",
    "        nc -= nc.min()\n",
    "        nc /= nc.max()\n",
    "    \n",
    "    return nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_novelty_curve(X, M=8, axis=0):\n",
    "    \"\"\"\n",
    "    Computes the novelty curve from the structural features.\n",
    "\n",
    "    Args:\n",
    "    - X (np.array): Structural features.\n",
    "    - M (int, optional): Size of Gaussian kernel. Default is 8.\n",
    "    - axis (int, optional): Axis along which to compute the difference. Default is 0.\n",
    "\n",
    "    Returns:\n",
    "    - nc (np.array): Novelty curve.\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "        X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "        compute_novelty_curve(X)\n",
    "    array([1., 1., 0.])\n",
    "    \"\"\"\n",
    "        # Determine the size of the feature matrix\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # Initialize the novelty curve with zeros\n",
    "    nc = np.zeros(N)\n",
    "\n",
    "    # Compute Euclidean distance between consecutive feature vectors to capture novelty\n",
    "    for i in range(N - 1):\n",
    "        nc[i] = distance.euclidean(X[i, :], X[i + 1, :])\n",
    "\n",
    "    # Normalize the novelty curve to a range [0, 1]\n",
    "    nc += np.abs(nc.min())\n",
    "    nc /= float(nc.max())\n",
    "    \n",
    "    return nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the vectorized method to ensure it works correctly\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "nc_vectorized = compute_novelty_curve_optimized(X)\n",
    "nc_vectorized\n",
    "\n",
    "# Let's test the original method to ensure it works correctly\n",
    "nc_original = compute_novelty_curve(X)\n",
    "\n",
    "# Run the approximate assertions\n",
    "assert np.allclose(nc_original, nc_vectorized), \"Original and vectorized methods do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original method: 1.41 seconds\n",
      "Vectorized method: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark the original method with a large feature matrix \n",
    "repetitions = 2\n",
    "X = np.random.rand(100000, 10)  # 500 data points with 10 dimensions\n",
    "\n",
    "time_original = timeit.timeit(lambda: compute_novelty_curve(X), number=repetitions)\n",
    "\n",
    "# Benchmark the vectorized method with a large feature matrix\n",
    "time_vectorized = timeit.timeit(lambda: compute_novelty_curve_optimized(X), number=repetitions)\n",
    "\n",
    "print(\"Original method: {:.2f} seconds\".format(time_original))\n",
    "print(\"Vectorized method: {:.2f} seconds\".format(time_vectorized))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumculative Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5 ms ± 42.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "12.7 µs ± 94.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "def cummulative_sum_Q(R):\n",
    "    len_x, len_y = R.shape\n",
    "    Q = np.zeros((len_x + 2, len_y + 2))\n",
    "    for i in range(len_x):\n",
    "        for j in range(len_y):\n",
    "            Q[i+2, j+2] = max(\n",
    "                    Q[i+1, j+1],\n",
    "                    Q[i, j+1],\n",
    "                    Q[i+1, j]) + R[i, j]\n",
    "    return np.max(Q)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def cummulative_sum_Q_numba(R):\n",
    "    len_x, len_y = R.shape\n",
    "    Q = np.zeros((len_x + 2, len_y + 2))\n",
    "    for i in range(len_x):\n",
    "        for j in range(len_y):\n",
    "            Q[i+2, j+2] = max(\n",
    "                    Q[i+1, j+1],\n",
    "                    Q[i, j+1],\n",
    "                    Q[i+1, j]) + R[i, j]\n",
    "    return np.max(Q)\n",
    "\n",
    "# Generate a random matrix to test and benchmark the functions\n",
    "R_test = np.random.rand(100, 100)\n",
    "\n",
    "# Benchmarking the original function\n",
    "%timeit cummulative_sum_Q(R_test)\n",
    "\n",
    "# Benchmarking the optimized function\n",
    "%timeit cummulative_sum_Q_numba(R_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def min_max_normalize(X, floor=0.0):\n",
    "    \"\"\"Min-max normalization.\"\"\"\n",
    "    X_min = X.min(axis=1, keepdims=True)\n",
    "    X_max = X.max(axis=1, keepdims=True)\n",
    "    norm_X = floor + (X - X_min) / (X_max - X_min)\n",
    "    return norm_X\n",
    "\n",
    "\n",
    "def lognormalize(X, floor=0.0, min_db=-80):\n",
    "    \"\"\"\n",
    "    Optimized version of the logarithmic scaling function for the feature matrix.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.array): Feature matrix where each row represents a feature vector.\n",
    "        floor (float, optional): Value to replace zeros in the matrix. Default is 0.0.\n",
    "        min_db (float, optional): Minimum decibel level for scaling. Default is -80.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Logarithmically scaled feature matrix.\n",
    "    \"\"\"\n",
    "    # Use numpy's where function to replace zeros with the floor value\n",
    "    X = np.where(X == 0, floor, X)\n",
    "\n",
    "    # Convert to dB scale using numpy's built-in functions\n",
    "    X_db = 10 * np.log10(np.abs(X))\n",
    "\n",
    "    # Clip to the specified minimum dB value using numpy's maximum function\n",
    "    X_db = np.maximum(X_db, X_db.max() + min_db)\n",
    "\n",
    "    return X_db\n",
    "\n",
    "\n",
    "def normalize(X, norm_type, floor=0.0, min_db=-80):\n",
    "    \"\"\"Normalizes the given matrix of features.\"\"\"\n",
    "    if isinstance(norm_type, str):\n",
    "        if norm_type == \"min_max\":\n",
    "            return min_max_normalize(X, floor=floor)\n",
    "        if norm_type == \"log\":\n",
    "            return lognormalize(X, floor=floor, min_db=min_db)\n",
    "    return librosa.util.normalize(X, norm=norm_type, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def min_max_normalize_numba(X, floor=0.0):\n",
    "    \"\"\"Numba-optimized min-max normalization.\"\"\"\n",
    "    X_min = np.zeros(X.shape[0])\n",
    "    X_max = np.zeros(X.shape[0])\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        X_min[i] = X[i, :].min()\n",
    "        X_max[i] = X[i, :].max()\n",
    "    \n",
    "    norm_X = floor + (X - X_min.reshape(-1, 1)) / (X_max.reshape(-1, 1) - X_min.reshape(-1, 1))\n",
    "    return norm_X\n",
    "\n",
    "def normalize_optimized(X, norm_type, floor=0.0, min_db=-80):\n",
    "    \"\"\"Optimized normalization of the given matrix of features.\"\"\"\n",
    "    if isinstance(norm_type, str):\n",
    "        if norm_type == \"min_max\":\n",
    "            return min_max_normalize_numba(X, floor=floor)\n",
    "    return librosa.util.normalize(X, norm=norm_type, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.random.rand(100, 100) + 1e-6  # Adding a small value to prevent log(0)\n",
    "\n",
    "# Test the original function\n",
    "X_test_original = normalize(X_test, norm_type=\"min_max\")\n",
    "\n",
    "# Test the optimized function\n",
    "X_test_optimized = normalize_optimized(X_test, norm_type=\"min_max\")\n",
    "\n",
    "# Run the approximate assertions\n",
    "assert np.allclose(X_test_original, X_test_optimized), \"Original and optimized methods do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=float)\n",
    "\n",
    "# test the original function\n",
    "X_test_original = normalize(X_test, norm_type=\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.28 µs ± 25.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.5 µs ± 3.81 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Benchmark the original function\n",
    "%timeit normalize(X_test, norm_type=\"min_max\")\n",
    "\n",
    "# Benchmark the optimized function\n",
    "%timeit normalize_optimized(X_test, norm_type=\"min_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Benchmark the original function\n",
    "%timeit normalize(X_test, norm_type=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Benchmark the original function\n",
    "%timeit normalize(X_test, norm_type=\"log\")\n",
    "\n",
    "# Benchmark the optimized function\n",
    "%timeit normalize_optimized(X_test, norm_type=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift matrix circularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_matrix_circularly(X):\n",
    "    \"\"\"\n",
    "    Shifts the matrix X circularly to get a time-lag matrix.\n",
    "\n",
    "    Args:\n",
    "    - X (np.array): Square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - L (np.array): Time-lag matrix.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    L = np.zeros(X.shape)\n",
    "    for i in range(N):\n",
    "        L[i, :] = np.asarray([X[(i + j) % N, j] for j in range(N)])\n",
    "    return L\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def shift_matrix_circularly_numba(X):\n",
    "    \"\"\"Numba-optimized calculation of circular shift to get a time-lag matrix.\"\"\"\n",
    "    N = X.shape[0]\n",
    "    L = np.zeros(X.shape)\n",
    "    for i in range(N):\n",
    "        L[i, :] = np.asarray([X[(i + j) % N, j] for j in range(N)])\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.77 ms ± 31.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "163 µs ± 926 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random matrix to test and benchmark the functions\n",
    "X_test = np.random.rand(100, 100)\n",
    "\n",
    "# Test the original function\n",
    "X_test_original = shift_matrix_circularly(X_test)\n",
    "\n",
    "# Test the optimized function\n",
    "X_test_optimized = shift_matrix_circularly_numba(X_test)\n",
    "\n",
    "# Run the approximate assertions\n",
    "assert np.allclose(X_test_original, X_test_optimized), \"Original and optimized methods do not match!\"\n",
    "# Benchmarking the original function\n",
    "%timeit shift_matrix_circularly(X_test)\n",
    "\n",
    "# Benchmarking the optimized function\n",
    "%timeit shift_matrix_circularly_numba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa PCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_extract_pcp(audio, sr, n_fft=4096, hop_len=int(4096 * 0.75),\n",
    "                      pcp_bins=84, pcp_norm=np.inf, pcp_f_min=27.5,\n",
    "                      pcp_n_octaves=6):\n",
    "    \"\"\"\n",
    "    Extract Pitch Class Profiles (PCP) from audio.\n",
    "\n",
    "    Args:\n",
    "    - audio (np.array): Audio waveform.\n",
    "    - sr (int): Sample rate of the audio.\n",
    "    - n_fft (int, optional): FFT size. Default is 4096.\n",
    "    - hop_len (int, optional): Hop length. Default is 75% of n_fft.\n",
    "    - pcp_bins (int, optional): Number of bins for PCP. Default is 84.\n",
    "    - pcp_norm (float, optional): Norm value for PCP. Default is infinity.\n",
    "    - pcp_f_min (float, optional): Minimum frequency for PCP. Default is 27.5Hz.\n",
    "    - pcp_n_octaves (int, optional): Number of octaves for PCP. Default is 6.\n",
    "\n",
    "    Returns:\n",
    "    - pcp (np.array): Extracted Pitch Class Profiles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate harmonic component from audio\n",
    "    audio_harmonic, _ = librosa.effects.hpss(audio)\n",
    "\n",
    "    # Compute Constant-Q transform of the harmonic component\n",
    "    pcp_cqt = np.abs(librosa.hybrid_cqt(audio_harmonic, sr=sr, hop_length=hop_len,\n",
    "                                        n_bins=pcp_bins, norm=pcp_norm, fmin=pcp_f_min)) ** 2\n",
    "\n",
    "    # Compute PCP from the CQT\n",
    "    pcp = librosa.feature.chroma_cqt(C=pcp_cqt, sr=sr, hop_length=hop_len,\n",
    "                                     n_octaves=pcp_n_octaves, fmin=pcp_f_min).T\n",
    "\n",
    "    return pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_audio_extract_pcp(audio, sr, n_fft=4096, hop_len=int(4096 * 0.75),\n",
    "                                pcp_bins=84, pcp_norm=np.inf, pcp_f_min=27.5,\n",
    "                                pcp_n_octaves=6):\n",
    "    \"\"\"\n",
    "    Extract Pitch Class Profiles (PCP) from audio using optimized methods.\n",
    "\n",
    "    Args:\n",
    "    - audio (np.array): Audio waveform.\n",
    "    - sr (int): Sample rate of the audio.\n",
    "    - n_fft (int, optional): FFT size. Default is 4096.\n",
    "    - hop_len (int, optional): Hop length. Default is 75% of n_fft.\n",
    "    - pcp_bins (int, optional): Number of bins for PCP. Default is 84.\n",
    "    - pcp_norm (float, optional): Norm value for PCP. Default is infinity.\n",
    "    - pcp_f_min (float, optional): Minimum frequency for PCP. Default is 27.5Hz.\n",
    "    - pcp_n_octaves (int, optional): Number of octaves for PCP. Default is 6.\n",
    "\n",
    "    Returns:\n",
    "    - pcp (np.array): Extracted Pitch Class Profiles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate harmonic component from audio\n",
    "    audio_harmonic, _ = librosa.effects.hpss(audio)\n",
    "\n",
    "    # Compute Constant-Q transform of the harmonic component\n",
    "    pcp_cqt = np.abs(librosa.hybrid_cqt(audio_harmonic, sr=sr, hop_length=hop_len,\n",
    "                                        n_bins=pcp_bins, norm=pcp_norm, fmin=pcp_f_min)) ** 2\n",
    "\n",
    "    # Compute PCP from the CQT\n",
    "    pcp = librosa.feature.chroma_cqt(C=pcp_cqt, sr=sr, hop_length=hop_len,\n",
    "                                     n_octaves=pcp_n_octaves, fmin=pcp_f_min).T\n",
    "\n",
    "    return pcp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/Users/nimamanaf/Library/CloudStorage/GoogleDrive-ndizbin14@ku.edu.tr/My Drive/Techno/technob/docs/examples/cse.WAV\"\n",
    "audio_data, sr = librosa.load(audio_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_audio_extract_pcp(audio, sr, n_fft=4096, hop_len=int(4096 * 0.75),\n",
    "                                pcp_bins=84, pcp_norm=np.inf, pcp_f_min=27.5,\n",
    "                                pcp_n_octaves=6):\n",
    "    \"\"\"\n",
    "    Extract Pitch Class Profiles (PCP) from audio with optimizations.\n",
    "\n",
    "    Args:\n",
    "    - audio (np.array): Audio waveform.\n",
    "    - sr (int): Sample rate of the audio.\n",
    "    - n_fft (int, optional): FFT size. Default is 4096.\n",
    "    - hop_len (int, optional): Hop length. Default is 75% of n_fft.\n",
    "    - pcp_bins (int, optional): Number of bins for PCP. Default is 84.\n",
    "    - pcp_norm (float, optional): Norm value for PCP. Default is infinity.\n",
    "    - pcp_f_min (float, optional): Minimum frequency for PCP. Default is 27.5Hz.\n",
    "    - pcp_n_octaves (int, optional): Number of octaves for PCP. Default is 6.\n",
    "\n",
    "    Returns:\n",
    "    - pcp (np.array): Extracted Pitch Class Profiles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate harmonic component from audio with reduced margin\n",
    "    audio_harmonic, _ = librosa.effects.hpss(audio, margin=(1, 4))\n",
    "\n",
    "    # Compute Constant-Q transform of the harmonic component with increased hop length\n",
    "    pcp_cqt = np.abs(librosa.cqt(audio_harmonic, sr=sr, hop_length=hop_len * 2,\n",
    "                                 n_bins=pcp_bins, norm=pcp_norm, fmin=pcp_f_min)) ** 2\n",
    "\n",
    "    # Compute PCP from the CQT\n",
    "    pcp = librosa.feature.chroma_cqt(C=pcp_cqt, sr=sr, hop_length=hop_len * 2,\n",
    "                                     n_octaves=pcp_n_octaves, fmin=pcp_f_min).T\n",
    "\n",
    "    return pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original method: 18.75 seconds\n",
      "Optimized method: 18.15 seconds\n"
     ]
    }
   ],
   "source": [
    "repetitions = 1\n",
    "\n",
    "# Benchmark the original method\n",
    "time_original = timeit.timeit(lambda: audio_extract_pcp(audio_data, sr), number=repetitions)\n",
    "# Benchmark the optimized method\n",
    "time_optimized = timeit.timeit(lambda: optimized_audio_extract_pcp(audio_data, sr), number=repetitions)\n",
    "\n",
    "print(\"Original method: {:.2f} seconds\".format(time_original))\n",
    "print(\"Optimized method: {:.2f} seconds\".format(time_optimized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
