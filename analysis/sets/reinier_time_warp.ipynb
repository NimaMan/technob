{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "Here we are going to to analyze the Reiner Zonneveld's time warp perfoamcne. \n",
    "\n",
    "# Load the data\n",
    "we will consider this part of the performance: \n",
    "01:31:00 DJ Promo - My underground madness\n",
    "01:33:03 Age of Love - Age of Love [some RMX or sped up version]\n",
    "01:36:00 Reinier Zonneveld & Angerfist - Fist on Acid\n",
    "01:41:00 Miro - Shining (Reinier Zonneveld RMX)\n",
    "\n",
    "# Analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/Users/nimamanaf/Desktop/Music/Reiner Zonneveld - Time Warp 2023/Reinier Zonneveld - Time Warp 2023.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio, clear_output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "class DJAnalysis:\n",
    "    def __init__(self, audio, sr=None, info=None):\n",
    "        if info is not None:\n",
    "            self.song_starts = self.convert_text_to_song_info(info)\n",
    "            self.song_starts_seconds = list(self.song_starts.keys())\n",
    "            self.start = self.song_starts_seconds[0]\n",
    "            self.duration = self.song_starts_seconds[-1] - self.start\n",
    "        if isinstance(audio, str):\n",
    "            self.y, self.sr = librosa.load(audio, duration=self.duration, offset=self.start)\n",
    "        else:\n",
    "            self.y = audio\n",
    "            self.sr = sr\n",
    "        \n",
    "        self.tempo = None\n",
    "        self.key = None\n",
    "        self.energy = None\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_seconds(time):\n",
    "        \"\"\"\n",
    "        Converts a time string in the format \"hh:mm:ss\" to seconds.\n",
    "        \"\"\"\n",
    "        time = time.split(':')\n",
    "        return int(time[0]) * 3600 + int(time[1]) * 60 + int(time[2])\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_text_to_song_info(text):\n",
    "        song_info = {}\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.split(' ')\n",
    "            if len(parts) >= 3:\n",
    "                time_parts = parts[0].split(':')\n",
    "                if len(time_parts) == 3:\n",
    "                    hours = int(time_parts[0])\n",
    "                    minutes = int(time_parts[1])\n",
    "                    seconds = int(time_parts[2])\n",
    "                    start_time_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "                    song_name = ' '.join(parts[2:])\n",
    "                    song_info[start_time_seconds] = song_name\n",
    "        \n",
    "        return song_info\n",
    "    \n",
    "    def get_sliding_tempo(self, window_size=30, window_step=5):\n",
    "        \"\"\"\n",
    "        This function calculates the tempo every 10 seconds with an sliding window of 5 seconds.\n",
    "        :param y: audio time series\n",
    "        :param sr: sampling rate of `y`\n",
    "        :param window_size: size of the window in seconds\n",
    "        :param window_step: step of the window in seconds\n",
    "        :return: a list of tuples with the tempo and the time in seconds\n",
    "        \"\"\"\n",
    "        y, sr = self.y, self.sr\n",
    "        # get the total time of the track in seconds\n",
    "        total_time = librosa.get_duration(y=y, sr=sr)\n",
    "        # calculate the number of windows \n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        # initialize the list of tuples\n",
    "        tempo_list = []\n",
    "        # iterate over the windows\n",
    "        for i in range(num_windows):\n",
    "            # get the start and end time of the window\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            # calculate the tempo\n",
    "            tempo = librosa.beat.beat_track(y=y[start*sr:end*sr], sr=sr)[0]\n",
    "            # append the tuple\n",
    "            tempo_list.append((tempo, start))\n",
    "        return tempo_list\n",
    "    \n",
    "    def get_sliding_energy(self, window_size=30, window_step=5):\n",
    "        # Similar to get_sliding_tempo, but for RMS energy\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        energy_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            rms_energy = np.mean(librosa.feature.rms(y=self.y[start*self.sr:end*self.sr]))\n",
    "            energy_list.append((rms_energy, start))\n",
    "        return energy_list\n",
    "\n",
    "    def get_sliding_key(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        key_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            chroma = librosa.feature.chroma_cqt(y=self.y[start*self.sr:end*self.sr], sr=self.sr)\n",
    "            key = np.argmax(np.sum(chroma, axis=1))\n",
    "            key_list.append((key, start))\n",
    "        return key_list\n",
    "    \n",
    "    def get_sliding_spectral_centroid(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        centroid_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            centroid = np.mean(librosa.feature.spectral_centroid(y=self.y[start*self.sr:end*self.sr], sr=self.sr))\n",
    "            centroid_list.append((centroid, start))\n",
    "        return centroid_list\n",
    "\n",
    "    def get_sliding_spectral_bandwidth(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        bandwidth_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=self.y[start*self.sr:end*self.sr], sr=self.sr))\n",
    "            bandwidth_list.append((bandwidth, start))\n",
    "        return bandwidth_list\n",
    "\n",
    "    def get_sliding_hnr(self, window_size=30, window_step=5):\n",
    "        # HNR might be more computationally intensive, so this method might be slower\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        hnr_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            hnr_value = librosa.effects.harmonic(self.y[start*self.sr:end*self.sr])[0]\n",
    "            hnr_list.append((hnr_value, start))\n",
    "        return hnr_list\n",
    "\n",
    "    def get_sliding_zero_crossing_rate(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        zcr_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            zcr = np.mean(librosa.feature.zero_crossing_rate(self.y[start*self.sr:end*self.sr]))\n",
    "            zcr_list.append((zcr, start))\n",
    "        return zcr_list\n",
    "    \n",
    "    def get_sliding_spectral_contrast(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        contrast_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(y=self.y[start*self.sr:end*self.sr], sr=self.sr), axis=1)\n",
    "            contrast_list.append((contrast, start))\n",
    "        return contrast_list\n",
    "\n",
    "    def get_band_energy_ratios(self, window_size=30, window_step=5):\n",
    "        total_time = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        num_windows = int(np.ceil((total_time - window_size) / window_step))\n",
    "        bands_list = []\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_step\n",
    "            end = start + window_size\n",
    "            D = np.abs(librosa.stft(self.y[start*self.sr:end*self.sr]))\n",
    "            band_energy = [np.mean(D[i]) for i in [range(0, 22), range(22, 45), range(45, 102)]]\n",
    "            bands_list.append((band_energy, start))\n",
    "        return bands_list\n",
    "\n",
    "    def extract_segment_from_time(self, start_time, duration=None):\n",
    "        \"\"\"\n",
    "        Extracts a segment of the audio based on a start time and duration (in seconds). If the duration is not provided, the segment is extracted until the end of the audio.\n",
    "        \"\"\"\n",
    "        if duration is None:\n",
    "            duration = len(self.y) / self.sr - start_time\n",
    "        return self.y[start_time*self.sr:(start_time+duration)*self.sr]\n",
    "\n",
    "    def get_segments(self, ):\n",
    "        \"\"\"\n",
    "        Extracts segments of the audio based on the song start times.\n",
    "        \"\"\"\n",
    "        segments = []\n",
    "        for idx, start_time in enumerate(self.song_starts_seconds):\n",
    "            if idx<len(self.song_starts_seconds)-1:\n",
    "                duration = self.song_starts_seconds[idx+1] - start_time\n",
    "            else:\n",
    "                duration = None\n",
    "            segments.append(self.extract_segment_from_time(start_time, duration))\n",
    " \n",
    "    def extract_tempo(self):\n",
    "        onset_env = librosa.onset.onset_strength(y=self.y, sr=self.sr)\n",
    "        self.tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=self.sr)\n",
    "        return self.tempo\n",
    "\n",
    "    def extract_key(self):\n",
    "        chroma = librosa.feature.chroma_cqt(y=self.y, sr=self.sr)\n",
    "        self.key = librosa.key(chroma)[0]  # Only the key, not the scale\n",
    "        return self.key\n",
    "\n",
    "    def extract_energy(self):\n",
    "        rms_energy = librosa.feature.rms(y=self.y)\n",
    "        self.energy = rms_energy[0]\n",
    "        return self.energy\n",
    "\n",
    "    def visualize_waveform(self, start_time=None, duration=None):\n",
    "        \"\"\"\n",
    "        Visualizes the waveform of a segment specified by start_time and duration.\n",
    "        If start_time is None, it visualizes from the start of the audio.\n",
    "        If duration is None, it visualizes until the end of the audio.\n",
    "        \"\"\"\n",
    "\n",
    "        if start_time is None:\n",
    "            start_time = 0\n",
    "\n",
    "        # Calculate start and end sample\n",
    "        start_sample = int(start_time * self.sr)\n",
    "\n",
    "        if duration is None:\n",
    "            end_sample = len(self.y)\n",
    "        else:\n",
    "            end_sample = start_sample + int(duration * self.sr)\n",
    "\n",
    "        # Ensure we don't exceed the audio's length\n",
    "        end_sample = min(end_sample, len(self.y))\n",
    "\n",
    "        # Extract segment\n",
    "        y_segment = self.y[start_sample:end_sample]\n",
    "\n",
    "        # Time axis for segment\n",
    "        time_segment = np.linspace(start_time, start_time + (end_sample - start_sample) / self.sr, len(y_segment))\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=time_segment, y=y_segment, mode='lines', name='Waveform'))\n",
    "\n",
    "        fig.update_layout(title='Waveform Segment', xaxis_title='Time (s)', yaxis_title='Amplitude')\n",
    "        fig.show()\n",
    "\n",
    "    def visualize_features(self, features=None, window_size=30, window_step=5):\n",
    "\n",
    "        self.visualize_waveform()\n",
    "\n",
    "        feature_methods = {\n",
    "            \"tempo\": self.get_sliding_tempo,\n",
    "            \"energy\": self.get_sliding_energy,\n",
    "            \"key\": self.get_sliding_key,\n",
    "            \"spectral centroid\": self.get_sliding_spectral_centroid,\n",
    "            \"spectral bandwidth\": self.get_sliding_spectral_bandwidth,\n",
    "            \"hnr\": self.get_sliding_hnr,\n",
    "            \"zero crossing rate\": self.get_sliding_zero_crossing_rate,\n",
    "            \"spectral contrast\": self.get_sliding_spectral_contrast,\n",
    "            \"band energy ratios\": self.get_band_energy_ratios\n",
    "        }\n",
    "        \n",
    "        if features is None:\n",
    "            features = feature_methods.keys()\n",
    "        \n",
    "        for feature in features:\n",
    "            print(f\"Extracting {feature}...\")\n",
    "            data_list = feature_methods[feature](window_size, window_step)\n",
    "            times = [t[1] for t in data_list]\n",
    "            values = [t[0] for t in data_list]\n",
    "            \n",
    "            fig = go.Figure(data=[go.Scatter(x=times, y=values, mode='lines', name=feature.capitalize())])\n",
    "            fig.update_layout(title=f\"{feature.capitalize()}\", xaxis_title='Time (s)', yaxis_title=feature.capitalize())\n",
    "            fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info = '''\n",
    "01:31:00 DJ Promo - My underground madness\n",
    "01:33:03 Age of Love - Age of Love [some RMX or sped up version]\n",
    "01:36:00 Reinier Zonneveld & Angerfist - Fist on Acid\n",
    "01:41:00 Miro - Shining (Reinier Zonneveld RMX)\n",
    "'''\n",
    "dj = DJAnalysis(audio_path, sr=None, info=info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.visualize_features(features=None, window_size=30, window_step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.visualize_waveform(start_time=120, duration=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the audio making the widget size cover the whole screen\n",
    "display(Audio(audio_path, autoplay=True, rate=dj.sr), display_id='audio')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the audio file\n",
    "song = AudioSegment.from_wav(\"/Users/nimamanaf/Library/CloudStorage/GoogleDrive-ndizbin14@ku.edu.tr/My Drive/Techno/technob/docs/examples/cse.WAV\")\n",
    "\n",
    "# Play the audio file\n",
    "play(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
